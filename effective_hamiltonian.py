import numpy as np
import matplotlib.pyplot as plt
from scipy.sparse import spdiags

# load npy file generated by DQMC
data = np.load("1575600344.npy", allow_pickle=True)

data = data[:70000]


def conf(v):
    # Construct 1D space-time spin field out of hubbard-stratonovich field by reshapping.
    s = v[0]
    for i in range(len(v)-1):
        s = np.concatenate((s, v[i+1]))
    s = np.array([s])
    return s


def generateJ(v, m, M):
    # generating J matrix out of few free parameters due to symmetry (translational symmetry)
    M = symmetry(v, M)  # applying symmetry on matrix
    data = np.array([[j for i in range(m)] for j in M])
    diags = np.array([i for i in range(m)])
    J = spdiags(data, diags, m, m).toarray()
    J = (J + J.T)  # symmetrize J matrix
    return J


def initialize_effectiveJ(v, method):
    # method = 1 : randomly initializing the J free parameters
    # method = 2 : initializing the J free parameters knowing the
    # exponential behaviour of the J along time and space.
    N = np.shape(v)[0]*np.shape(v)[1]
    if method == 1:
        M = np.random.random(size=N)
    elif method == 2:
        J = np.zeros(np.shape(v))
        for i in range(np.shape(v)[0]):
            for j in range(np.shape(v)[1]):
                J[i, j] = np.exp(-0.5*i-.5*j)

        J = (np.flip(J, axis=0)+J)/2
        J = (np.flip(J, axis=1)+J)/2
        M = np.reshape(J, N)
    else:
        print("select the proper method")
    return M


def symmetry(v, M):
    # apply translational symmetry on free parameters
    shapeM = np.shape(M)
    M = np.reshape(M, np.shape(v))
    M = (np.flip(M, axis=1) + M)/2
    M = (np.flip(M, axis=0) + M)/2
    M = np.reshape(M, shapeM)
    return M


def gradient(E0, Heff, S, J, method=1):
    # gradient of cost function. if method == 1, the cost function
    # is relative entropy (its convex and recommended). else the method
    # is standard deviation.
    alpha = E0 + np.trace(S.dot(J).dot(S.T))
    if method == 1:
        grad_del = ((alpha - np.sum(Heff))/(alpha*(1-alpha)))*S.T.dot(S)[0, :]
    else:
        grad_del = (alpha - np.sum(Heff))*S.T.dot(S)[0, :]
    return grad_del


zl = []
cc = []
for z, v in data:
    cc.append(conf(v)[0])
    zl.append(z)

S = np.array(cc)
Heff = np.array(zl)

InJ = initialize_effectiveJ(v, method=1)
E0 = np.mean(zl)
m = np.shape(v)[0]*np.shape(v)[1]
J = generateJ(v, m, InJ)
plt.plot(InJ)
plt.title("initialized free parameters of J matrix")
plt.show()

r = 100
gl = []
dl = 500
while np.abs(r) > 0.000001:
    alpha = 1000  # gradient step
    g = 0
    for i in range(1, int(data.shape[0]/dl)):
        g += gradient(E0, Heff[(i-1)*dl:i*dl], S[(i-1)*dl:i*dl, :], J, method=1)

    g = np.reshape(g, np.shape(InJ))
    r = np.mean(g)
    gl.append(r)
    print(r)
    InJ -= g * alpha
    J = generateJ(v, m, InJ)

Jreshaped = np.reshape(J[0][:], np.shape(v))
plt.plot(Jreshaped[0])
plt.title("spacial behaviour of effective hamiltonian")
plt.show()


plt.imshow(J)
plt.title("J matrix")
plt.show()

plt.plot(J[0][1:])
plt.title("first row of J matrix")
plt.show()

plt.plot(np.abs(gl))
plt.title("cost")
plt.show()

np.save("J"+str(np.shape(data)[0])+".npy", J)
